{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98f87a0b-53d3-46e7-a80e-387453a56fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from datasets import load_dataset,Dataset\n",
    "import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc84138-fa36-4e59-89d5-7e1bbb8c7eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40707c0e-4026-4e72-9dbc-4d280c1608b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = \"cuda\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "\n",
    "class CIFAR10(torch.utils.data.Dataset):\n",
    "    def collectImage(self, img):\n",
    "        t = np.array(img)\n",
    "        return t.transpose((2,0,1))\n",
    "    def __init__(self, split=\"train\"):\n",
    "        if split == \"train\":\n",
    "            dataset = torchvision.datasets.CIFAR10(\"../data/\", download=True)\n",
    "        else:\n",
    "            dataset = torchvision.datasets.CIFAR10(\"../data/\", download=True, train=False)\n",
    "        self.data = torch.FloatTensor(np.stack([self.collectImage(i[0]) for i in dataset])/255).to(device)\n",
    "        self.label = torch.LongTensor(np.array([i[1] for i in dataset], dtype=np.int64)).to(device)\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c7e8612-8c4f-4fcd-8e34-115f11e480f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "644a327d-4a32-452d-82f7-a24a1598b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTConfig, ViTModel\n",
    "configuration = ViTConfig(hidden_size = 128,\n",
    "                          num_hidden_layers = 2,\n",
    "                          num_attention_heads = 2,\n",
    "                         intermediate_size=128,\n",
    "                         hidden_dropout_prob=0.1)\n",
    "model = ViTModel(configuration).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af823821-75f5-44e9-9609-3d12114cbe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTModel(\n",
       "  (embeddings): ViTEmbeddings(\n",
       "    (patch_embeddings): ViTPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 128, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): ViTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-1): 2 x ViTLayer(\n",
       "        (attention): ViTAttention(\n",
       "          (attention): ViTSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTOutput(\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "  (pooler): ViTPooler(\n",
       "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88b1780b-c52a-4eab-848b-d366cf417cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339712"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a750622-fc3a-4cad-98a5-594cf2b60d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
