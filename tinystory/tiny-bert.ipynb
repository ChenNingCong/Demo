{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a3149-c16b-4635-ba52-52200d92c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import accelerate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06875418-f27b-4d3a-98d3-cfa85d190953",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /mnt/data/ml-data -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0637f-0818-4a0a-bc47-aabefbdd55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37d7c2-4237-435c-a7ed-68ced158a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, GPTNeoForCausalLM\n",
    "device=\"cuda\"\n",
    "model_checkpoint = \"roneneldan/TinyStories-1M\"\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "#model =  AutoModel.from_config(config).to(device)\n",
    "model =   GPTNeoForCausalLM(config).to(device)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        print(p)\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99ac25-0d9f-4677-958b-37e8d43ab2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"/mnt/data/ml-data/tinystory-tokenized/\"):\n",
    "    dataset = load_dataset('roneneldan/TinyStories', cache_dir=\"/mnt/data/ml-data\")\n",
    "    def transform(examples):\n",
    "        return tokenizer(examples['text'], truncation=True, max_length=512)\n",
    "    tokenized_dataset = dataset[\"train\"].map(transform, batched=True).remove_columns(\"text\")\n",
    "    tokenized_dataset.save_to_disk(\"/mnt/data/ml-data/tinystory-tokenized\")\n",
    "else:\n",
    "    tokenized_dataset = load_from_disk(\"/mnt/data/ml-data/tinystory-tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b5008-27ec-41c1-8f5c-695d99e8429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "#DataCollatorWithPadding(tokenizer, padding='max_length', pad_to_multiple_of=8) \n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656429f9-3109-4f5b-bfaf-355cdc0280cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, get_cosine_schedule_with_warmup\n",
    "batch_size=8\n",
    "steps_per_epoch = len(tokenized_dataset) /batch_size\n",
    "num_train_epochs = 30\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/mnt/data/tiny-bert\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    logging_dir='/mnt/data/tiny-bert/logs',\n",
    "    per_device_train_batch_size=batch_size,\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.9,0.99))\n",
    "warmup_iters = 2000 # not super necessary potentially\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_iters, num_training_steps=num_train_epochs * steps_per_epoch)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    #eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, scheduler)\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c934f8b-5f87-40dc-aafb-5ec5955c7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "model = model.to(\"cuda\")\n",
    "def generator(text, max_length=30, num_return_sequences=1):\n",
    "    model_inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    greedy_output = model.generate(**model_inputs, max_length=160,\n",
    "                                  num_beams=5,\n",
    "                                   do_sample=True,no_repeat_ngram_size=2,\n",
    "    top_k=0,\n",
    "    temperature=1,\n",
    "    early_stopping=True)\n",
    "    return tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "# generate 40 new tokens\n",
    "\n",
    "def generate(text):\n",
    "    result = generator(text, max_length=30, num_return_sequences=1)\n",
    "    return result\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=gr.Textbox(lines=5, label=\"Input Text\"),\n",
    "    outputs=gr.Textbox(label=\"Generated Text\"),\n",
    "    examples = [\"Once upon a time\",\"\"]\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fac2ad-5456-403d-a558-8ce3ec2f6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eaab3d-9974-48cb-926c-a0a98144eabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
